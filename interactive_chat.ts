/**
 * Interactive Chat with LLM
 * 
 * Real-time chat where you can type your own prompts and get immediate responses
 */

import { GeminiLLM, Config } from './src/llm/gemini-llm';
import * as readline from 'readline';

function loadConfig(): Config {
    try {
        const config = require('./config/config.json');
        return config;
    } catch (error) {
        console.error('‚ùå Error loading config/config.json');
        process.exit(1);
    }
}

async function startChat() {
    console.log('ü§ñ Interactive LLM Chat');
    console.log('========================\n');
    
    const config = loadConfig();
    const llm = new GeminiLLM(config);
    
    // Test connection
    console.log('üîå Testing connection...');
    try {
        const connected = await llm.testConnection();
        if (!connected) {
            console.log('‚ùå Connection failed');
            return;
        }
        console.log('‚úÖ Connected!\n');
    } catch (error) {
        console.log('‚ùå Connection error:', (error as Error).message);
        return;
    }
    
    const rl = readline.createInterface({
        input: process.stdin,
        output: process.stdout
    });
    
    console.log('üí¨ Type your prompts below. Type "exit" to quit.\n');
    
    const chat = () => {
        rl.question('You: ', async (input) => {
            if (input.toLowerCase() === 'exit') {
                console.log('\nüëã Goodbye!');
                rl.close();
                return;
            }
            
            if (input.trim() === '') {
                chat();
                return;
            }
            
            try {
                console.log('\nü§ñ Thinking...');
                const response = await llm.executeLLM(input);
                console.log(`\nü§ñ LLM: ${response}\n`);
            } catch (error) {
                console.log(`\n‚ùå Error: ${(error as Error).message}\n`);
            }
            
            chat();
        });
    };
    
    chat();
}

startChat().catch(console.error);
